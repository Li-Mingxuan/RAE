# Audio RAE Configuration - Spectrogram-based with Vision Encoder
# This config treats mel-spectrograms as images and uses DINOv2

stage_1:
  target: stage1.audio_rae.AudioRAE
  params:
    # Audio-specific parameters
    audio_type: 'spectrogram'  # Use spectrogram input
    sample_rate: 16000         # 16kHz sampling rate
    n_fft: 400                 # FFT window size
    hop_length: 160            # Hop length (10ms at 16kHz)
    n_mels: 128                # Number of mel bins
    max_duration: 10.0         # Maximum 10 seconds of audio
    
    # Encoder configuration (vision model for spectrograms)
    encoder_cls: 'SpectrogramEncoder'
    encoder_config_path: 'facebook/dinov2-base'
    encoder_input_size: 224    # Resize spectrogram to 224x224
    encoder_params:
      model_path: 'facebook/dinov2-base'
      mel_bins: 128
      normalize: True
    
    # Decoder configuration
    decoder_config_path: 'configs/decoder/ViTBase'
    decoder_patch_size: 16
    pretrained_decoder_path: null  # Set this to your trained decoder checkpoint
    
    # Training parameters
    noise_tau: 0.8
    reshape_to_2d: True
    normalization_stat_path: null  # Set after computing stats on your audio dataset
    eps: 1e-5

# GAN discriminator configuration for Stage 1 training
gan:
  target: disc.discriminator.Discriminator
  params:
    nc: 3  # 3 channels (spectrogram converted to RGB-like)
    ndf: 64
    n_layers: 3

# Training configuration
training:
  epochs: 100
  batch_size: 16
  learning_rate: 1e-4
  ema_decay: 0.9999
  gradient_accumulation_steps: 1
  
misc:
  latent_size: [768, 14, 14]  # Typical for DINOv2-base on 224x224 input
  num_classes: null  # Not using class conditioning for basic audio
